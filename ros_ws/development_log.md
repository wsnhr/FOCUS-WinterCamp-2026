环节一：配置开发环境
	装虚拟机，ubuntu20.04,ros,gazebo,vscode
	之前搞过双系统配置过这些，感觉虚拟机比双系统方便一点。
环节二：建立工作空间，进行简单仿真
	建立了一个工作空间，写环境变量
	看了宇树仓库的内容，clone了unitree_ros,unitree_guide,unitree_legged_msgs(这个在unitree_ros_to_real里面)
！！！！卡点1	尝试键盘控制
		launch调起仿真，rosrun调起junior_ctrl后，我怎么按键狗都不动。
		然后我以为是少clone了东西，或者是前面的操作有错误，试了半天还是不行
		拷打chatgpt,发现unitree_guide仓库里面的readme说要先按2让它站起来，按4让它走路状态，记得看readme.
环节三：走正方形脚本
	阅读源码，我把FSM的那几种状态直接发给chatgpt了，发现在move_base状态下是吃cmd_vel的，所以只要手动切到那个模式再开一个终端运行脚本就行。
！！！！卡点2	怎么切到move_base？
		按道理我按了5应该就可以切到的，但是rostopic info /cmd_vel又没有订阅者，然后又疯狂拷打chatgpt，发现cmakelists里面还有move_base相关，set(MOVE_BASE OFF)他把很多模式的“总电闸”给关了，这确实是牛逼的设计，但真的让我汗流浃背了，然后改了这个开关，重新编
		译了一次
	新建了一个包，里面放脚本
！！！！卡点3	狗发神经
		我的实现逻辑就是直走接转弯重复四次，结果狗连走直线都会偶尔摔倒，轨迹黄线是根波浪线，我一开始想是设置的速度问题，调整了下，直走好一点了，转弯完全不行
		1.直走接转弯会摔，我就让它直走完停一会再转弯；
		2.转弯速度不好把控，太快会摔，太慢狗就会扭腿转弯，
		然后我修改了几次脚本，让速度变成从零到一之间有加速度，但是狗一直不太听话，而且在一次测试明显会越来越差，感觉不是脚本的问题了，我就想换成作车会不会好一点，最后排查到控制器一直在报的超时warnning是会影响到仿真的，会导致发话题的频率不规律。解决方法就是
		给虚拟机多分几个核，他默认只有一个核，再尝试一次走得就比较可以了。
环节三：追踪红色方块
	本来想直接用gazebo的图形化界面放一个的，结果不能调方块的颜色，最后直接在world里面加了一个
	查看狗的模型发现既有urdf又有xacro，我就很奇怪为什么有两种模型文件，问ai知道urdf是xacro动态生成的，xacro里面有一个自带的深度相机，我就直接把它按到狗头位置，试了下可以看到天空在下面，又反过来装
	写这个脚本，将要求发给ai,要求提取红色，计算质心与面积，判断运动条件，噪点阈值。运行脚本发现效果不错，ai真牛逼(这里容我狡辩，之前我做过车牌提取的opencv实现，但和ros结合还是得ai，我学ai写的)
	特别的是不用手写 while 循环去“读相机”，ROS 帮你事件驱动。
环节四：自动避障
	一上来就没绷住，好像要使用雷达，可是我看包里也没有啊，就有一个超声波传感器，再看看宇树仓库point_lio_unilidar好像和雷达有关，视频看起来挺酷炫的，但是sdk是什么？！
	最后选的是比较好搞的2d雷达，看起来有点糖
	搞了个脚本，把数据清洗后压缩为10维，十个数据分别表示最近点的距离,只取前方180度
	突然发现有一堆依赖没装，之前双系统搞那些搞了好久，现在有点破防
	新建了一个虚拟环境装了PyTorch CPU+SB3 + Gymnasium + Tensorboard
	打包了一个env，打通了步进接口和重置接口
	可以看见狗在随机行走训练了，但每次reset的时候狗有几率散架
	
现在是30号0：20，我决定这次就做到这。
	
	
	
	
	
	
	
